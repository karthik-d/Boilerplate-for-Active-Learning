---
## MLP Parameters ##
# This specification trains an ensemble of Mini-DenseNet-121s for two rounds using DIB, one epoch each. 
# Set absolute paths, or relative to the root of this codebase (ROOT_DIR in config).
dataset: data/cifar10
data_format: npz
convert_labels_to_one_hot: true
model_file: mini-densenet121.model
reduce_lr_on_plateau:
  factor: 0.1
  patience: 5
  cooldown: 0
  min_lr: 0.0000001
optimizer:
  0:
    class_name: Adam
    config:
      learning_rate:
        0:  0.001
        20: 0.0001
        50: 0.00001
epochs: 1
steps_per_epoch:
  train: 10
  valid: 5
  test: 5
batch_size: 128
loss: categorical_crossentropy
shuffle: true

# Online image transformations using `ImageDataGenerator`
img_gen_params:
  width_shift_range: 0.125
  height_shift_range: 0.125
  horizontal_flip: true
  rotation_range: 15
  featurewise_std_normalization: true
  featurewise_center: true

## Ensemble Parameters (Deep Incremental Boosting) ##
ensemble_method:
  class_name: DIB
  params:
    subsequent_epochs: 1
    subsequent_optimizer:
      0:
        class_name: Adam
        config:
          learning_rate:
            0:  0.001
            10: 0.0001
            20: 0.00001
    freeze_old_layers: true
    insert_after: concatenate_34
    new_layers:
      - class_name: BatchNormalization
        config:
          axis: !!python/object/apply:tensorflow.python.training.tracking.data_structures.ListWrapper
          - - 3
          beta_constraint: null
          beta_initializer:
            class_name: Zeros
            config: {}
          beta_regularizer: null
          center: true
          dtype: float32
          epsilon: 1.1e-05
          gamma_constraint: null
          gamma_initializer:
            class_name: Ones
            config: {}
          gamma_regularizer: null
          momentum: 0.99
          moving_mean_initializer:
            class_name: Zeros
            config: {}
          moving_variance_initializer:
            class_name: Ones
            config: {}
          name: batch_normalization_37
          scale: true
          trainable: true
        inbound_nodes:
        - - - PREDECESSOR
            - 0
            - 0
            - {}
        name: batch_normalization_37
      - class_name: Activation
        config:
          activation: relu
          dtype: float32
          name: activation_37
          trainable: true
        inbound_nodes:
        - - - batch_normalization_37
            - 0
            - 0
            - {}
        name: activation_37
      - class_name: Conv2D
        config:
          activation: linear
          activity_regularizer: null
          bias_constraint: null
          bias_initializer:
            class_name: Zeros
            config: {}
          bias_regularizer: null
          data_format: channels_last
          dilation_rate: &id001 !!python/tuple
          - 1
          - 1
          dtype: float32
          filters: 12
          kernel_constraint: null
          kernel_initializer:
            class_name: VarianceScaling
            config:
              distribution: truncated_normal
              mode: fan_in
              scale: 2.0
              seed: null
          kernel_regularizer: null
          kernel_size: &id003 !!python/tuple
          - 3
          - 3
          name: conv2d_38
          padding: same
          strides: *id001
          trainable: true
          use_bias: false
        inbound_nodes:
        - - - activation_37
            - 0
            - 0
            - {}
        name: conv2d_38
      - class_name: Concatenate
        config:
          axis: -1
          dtype: float32
          name: concatenate_35
          trainable: true
        inbound_nodes:
        - - - PREDECESSOR
            - 0
            - 0
            - &id040 {}
          - - conv2d_38
            - 0
            - 0
            - *id040
        name: concatenate_35
    size: 2